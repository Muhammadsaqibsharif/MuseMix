{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEb2Dv6bJLUA",
        "outputId": "72ce39b5-45bd-4272-c47e-48e9c8cbc1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio git+https://github.com/openai/whisper.git groq spotipy requests transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "grGjmb2iJDhd",
        "outputId": "b48a3a01-ff01-4ecb-8455-4665765519cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c44774493c710b7d14.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://c44774493c710b7d14.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅ STEP 1: Install Required Packages (if needed)\n",
        "# !pip install -q gradio git+https://github.com/openai/whisper.git groq spotipy requests\n",
        "\n",
        "# ✅ STEP 2: Import Libraries\n",
        "import whisper\n",
        "import gradio as gr\n",
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "# Load from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access environment variables\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "client_id = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
        "client_secret = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
        "\n",
        "# If needed, set them explicitly\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "os.environ[\"SPOTIPY_CLIENT_ID\"] = client_id\n",
        "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = client_secret\n",
        "\n",
        "# ✅ STEP 4: Initialize Clients\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials())\n",
        "asr_model = whisper.load_model(\"base\")\n",
        "\n",
        "# ✅ STEP 5: Spotify Playlist\n",
        "def get_playlist(emotion, lang=\"english\", limit=5):\n",
        "    emotion_to_query = {\n",
        "        \"خوشی\": \"Pakistani upbeat songs\", \"اداسی\": \"Pakistani sad songs\",\n",
        "        \"غصہ\": \"Pakistani rock\", \"تھکاوٹ\": \"Pakistani lofi\",\n",
        "        \"جذباتی\": \"Pakistani romantic songs\", \"پر سکون\": \"Pakistani sufi music\",\n",
        "        \"happy\": \"feel good\", \"sad\": \"melancholy\", \"angry\": \"hard rock\", \"tired\": \"lofi\",\n",
        "        \"exhausted\": \"ambient\", \"nostalgic\": \"throwback\", \"motivated\": \"upbeat\",\n",
        "        \"demotivated\": \"healing\", \"excited\": \"party\", \"calm\": \"chill\", \"anxious\": \"relaxing\"\n",
        "    }\n",
        "    query = emotion_to_query.get(emotion.strip().lower(), \"chill\")\n",
        "    results = sp.search(q=query, type='track', limit=limit)\n",
        "    playlist = []\n",
        "    for track in results['tracks']['items']:\n",
        "        name = track['name']\n",
        "        artist = track['artists'][0]['name']\n",
        "        url = track['external_urls']['spotify']\n",
        "        entry = f\"🎵 {name} از {artist} → [سنیں]({url})\" if lang == \"urdu\" else f\"🎵 {name} by {artist} → [Listen]({url})\"\n",
        "        playlist.append(entry)\n",
        "    return playlist\n",
        "\n",
        "# ✅ STEP 6: Generate Poem\n",
        "def get_poem(emotion, lang):\n",
        "    prompt = (\n",
        "        f\"ایک دل کو چھو لینے والی اردو نظم لکھیں جو پاکستانی شاعری کے انداز میں ہو۔ جذبہ: {emotion}\"\n",
        "        if lang == \"urdu\"\n",
        "        else f\"Write a short free-verse poem in {lang} inspired by the emotion: {emotion}. Use deep feeling and vivid imagery.\"\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ✅ STEP 7: Mood GIF from Tenor\n",
        "def search_tenor_gif(mood):\n",
        "    try:\n",
        "        url = f\"https://g.tenor.com/v1/search?q={mood}&key=LIVDSRZULELA&limit=1\"\n",
        "        r = requests.get(url)\n",
        "        return r.json()['results'][0]['media'][0]['gif']['url']\n",
        "    except:\n",
        "        return \"https://media.tenor.com/images/0f1b67f2f74bba6d553332b26276a707/tenor.gif\"\n",
        "\n",
        "# ✅ STEP 8: Main Logic\n",
        "def analyze_emotion(language, audio_path):\n",
        "    if not audio_path:\n",
        "        return \"❌ کوئی آڈیو موصول نہیں ہوئی\" if language == \"urdu\" else \"❌ No audio file provided\", None\n",
        "\n",
        "    try:\n",
        "        result = asr_model.transcribe(audio_path, language=\"ur\" if language == \"urdu\" else \"en\")\n",
        "        text = result.get(\"text\", \"\").strip()\n",
        "        if not text:\n",
        "            return \"❌ آڈیو کو سمجھنے میں ناکامی\" if language == \"urdu\" else \"❌ Could not transcribe audio\", None\n",
        "\n",
        "        # Emotion detection prompt\n",
        "        emotion_list = [\"خوشی\", \"اداسی\", \"غصہ\", \"تھکاوٹ\", \"جذباتی\", \"پر سکون\"] if language == \"urdu\" else \\\n",
        "                       [\"happy\", \"sad\", \"angry\", \"tired\", \"exhausted\", \"nostalgic\", \"motivated\", \"demotivated\", \"excited\", \"calm\", \"anxious\"]\n",
        "\n",
        "        prompt = (\n",
        "            f\"مندرجہ ذیل عبارت کے مطابق جذبات کا اندازہ لگائیں۔ ان میں سے ایک کا انتخاب کریں: {emotion_list}.\\n\"\n",
        "            f\"عبارت: \\\"{text}\\\"\\n\"\n",
        "            f\"جواب میں لکھیں:\\n- Emotion:\\n- Reason:\"\n",
        "        ) if language == \"urdu\" else (\n",
        "            f\"From the following text, detect the most likely human emotion expressed.\\n\"\n",
        "            f\"Choose one emotion from: {emotion_list}.\\n\"\n",
        "            f\"Text: \\\"{text}\\\"\\n\"\n",
        "            f\"Respond with:\\n- Emotion:\\n- Reason:\"\n",
        "        )\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        emotion_analysis = response.choices[0].message.content.strip()\n",
        "        emotion_line = [line for line in emotion_analysis.splitlines() if \"Emotion\" in line]\n",
        "        if not emotion_line:\n",
        "            return \"❌ جذبہ شناخت نہ ہو سکا\" if language == \"urdu\" else \"❌ Could not detect emotion\", None\n",
        "\n",
        "        emotion = emotion_line[0].split(\":\")[1].strip()\n",
        "        playlist = get_playlist(emotion, language)\n",
        "        poem = get_poem(emotion, language)\n",
        "        gif_url = search_tenor_gif(emotion)\n",
        "\n",
        "        playlist_md = \"\\n\".join(playlist) if playlist else \"⚠️ کوئی گانا نہیں ملا\" if language == \"urdu\" else \"⚠️ No songs found.\"\n",
        "\n",
        "        # ✅ STEP 9: Return Beautifully Formatted Output\n",
        "        if language == \"urdu\":\n",
        "            output_text = f\"\"\"\n",
        "<div dir=\"rtl\" style=\"text-align: right; font-family: 'Noto Nastaliq Urdu', serif; font-size: 16px\">\n",
        "\n",
        "### 📋 متن\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### 🎭 جذباتی تجزیہ\n",
        "{emotion_analysis}\n",
        "\n",
        "---\n",
        "\n",
        "### 🎧 گانے (جذبہ: {emotion})\n",
        "{playlist_md}\n",
        "\n",
        "---\n",
        "\n",
        "### 📜 نظم\n",
        "{poem}\n",
        "\n",
        "</div>\n",
        "\"\"\"\n",
        "        else:\n",
        "            output_text = f\"\"\"\n",
        "### 📝 Transcription\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### 🎭 Emotion Analysis\n",
        "{emotion_analysis}\n",
        "\n",
        "---\n",
        "\n",
        "### 🎧 Playlist for *{emotion}*\n",
        "{playlist_md}\n",
        "\n",
        "---\n",
        "\n",
        "### 📜 Poem\n",
        "{poem}\n",
        "\"\"\"\n",
        "        return output_text, gif_url\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ خرابی: {str(e)}\" if language == \"urdu\" else f\"❌ Error: {str(e)}\", None\n",
        "\n",
        "# ✅ STEP 10: Gradio App\n",
        "gr.Interface(\n",
        "    fn=analyze_emotion,\n",
        "    inputs=[\n",
        "        gr.Radio([\"english\", \"urdu\"], label=\"🌐 Language / زبان منتخب کریں\"),\n",
        "        gr.Audio(type=\"filepath\", label=\"🎤 Upload or Record Voice\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"📋 Output\"),\n",
        "        gr.Image(label=\"🖼️ Mood GIF\")\n",
        "    ],\n",
        "    title=\"🎙️ Voice-to-Emotion: Pakistani Songs + Urdu Poetry\",\n",
        "    description=\"🎧 Upload voice → Transcribe → Detect emotion → Get a themed playlist, AI poem, and GIF 🎭\"\n",
        ").launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m7YscDQCLACt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
