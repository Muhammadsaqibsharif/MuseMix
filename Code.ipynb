{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEb2Dv6bJLUA",
        "outputId": "72ce39b5-45bd-4272-c47e-48e9c8cbc1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio git+https://github.com/openai/whisper.git groq spotipy requests transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "grGjmb2iJDhd",
        "outputId": "b48a3a01-ff01-4ecb-8455-4665765519cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c44774493c710b7d14.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://c44774493c710b7d14.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# âœ… STEP 1: Install Required Packages (if needed)\n",
        "# !pip install -q gradio git+https://github.com/openai/whisper.git groq spotipy requests\n",
        "\n",
        "# âœ… STEP 2: Import Libraries\n",
        "import whisper\n",
        "import gradio as gr\n",
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "# Load from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access environment variables\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "client_id = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
        "client_secret = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
        "\n",
        "# If needed, set them explicitly\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "os.environ[\"SPOTIPY_CLIENT_ID\"] = client_id\n",
        "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = client_secret\n",
        "\n",
        "# âœ… STEP 4: Initialize Clients\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials())\n",
        "asr_model = whisper.load_model(\"base\")\n",
        "\n",
        "# âœ… STEP 5: Spotify Playlist\n",
        "def get_playlist(emotion, lang=\"english\", limit=5):\n",
        "    emotion_to_query = {\n",
        "        \"Ø®ÙˆØ´ÛŒ\": \"Pakistani upbeat songs\", \"Ø§Ø¯Ø§Ø³ÛŒ\": \"Pakistani sad songs\",\n",
        "        \"ØºØµÛ\": \"Pakistani rock\", \"ØªÚ¾Ú©Ø§ÙˆÙ¹\": \"Pakistani lofi\",\n",
        "        \"Ø¬Ø°Ø¨Ø§ØªÛŒ\": \"Pakistani romantic songs\", \"Ù¾Ø± Ø³Ú©ÙˆÙ†\": \"Pakistani sufi music\",\n",
        "        \"happy\": \"feel good\", \"sad\": \"melancholy\", \"angry\": \"hard rock\", \"tired\": \"lofi\",\n",
        "        \"exhausted\": \"ambient\", \"nostalgic\": \"throwback\", \"motivated\": \"upbeat\",\n",
        "        \"demotivated\": \"healing\", \"excited\": \"party\", \"calm\": \"chill\", \"anxious\": \"relaxing\"\n",
        "    }\n",
        "    query = emotion_to_query.get(emotion.strip().lower(), \"chill\")\n",
        "    results = sp.search(q=query, type='track', limit=limit)\n",
        "    playlist = []\n",
        "    for track in results['tracks']['items']:\n",
        "        name = track['name']\n",
        "        artist = track['artists'][0]['name']\n",
        "        url = track['external_urls']['spotify']\n",
        "        entry = f\"ğŸµ {name} Ø§Ø² {artist} â†’ [Ø³Ù†ÛŒÚº]({url})\" if lang == \"urdu\" else f\"ğŸµ {name} by {artist} â†’ [Listen]({url})\"\n",
        "        playlist.append(entry)\n",
        "    return playlist\n",
        "\n",
        "# âœ… STEP 6: Generate Poem\n",
        "def get_poem(emotion, lang):\n",
        "    prompt = (\n",
        "        f\"Ø§ÛŒÚ© Ø¯Ù„ Ú©Ùˆ Ú†Ú¾Ùˆ Ù„ÛŒÙ†Û’ ÙˆØ§Ù„ÛŒ Ø§Ø±Ø¯Ùˆ Ù†Ø¸Ù… Ù„Ú©Ú¾ÛŒÚº Ø¬Ùˆ Ù¾Ø§Ú©Ø³ØªØ§Ù†ÛŒ Ø´Ø§Ø¹Ø±ÛŒ Ú©Û’ Ø§Ù†Ø¯Ø§Ø² Ù…ÛŒÚº ÛÙˆÛ” Ø¬Ø°Ø¨Û: {emotion}\"\n",
        "        if lang == \"urdu\"\n",
        "        else f\"Write a short free-verse poem in {lang} inspired by the emotion: {emotion}. Use deep feeling and vivid imagery.\"\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# âœ… STEP 7: Mood GIF from Tenor\n",
        "def search_tenor_gif(mood):\n",
        "    try:\n",
        "        url = f\"https://g.tenor.com/v1/search?q={mood}&key=LIVDSRZULELA&limit=1\"\n",
        "        r = requests.get(url)\n",
        "        return r.json()['results'][0]['media'][0]['gif']['url']\n",
        "    except:\n",
        "        return \"https://media.tenor.com/images/0f1b67f2f74bba6d553332b26276a707/tenor.gif\"\n",
        "\n",
        "# âœ… STEP 8: Main Logic\n",
        "def analyze_emotion(language, audio_path):\n",
        "    if not audio_path:\n",
        "        return \"âŒ Ú©ÙˆØ¦ÛŒ Ø¢ÚˆÛŒÙˆ Ù…ÙˆØµÙˆÙ„ Ù†ÛÛŒÚº ÛÙˆØ¦ÛŒ\" if language == \"urdu\" else \"âŒ No audio file provided\", None\n",
        "\n",
        "    try:\n",
        "        result = asr_model.transcribe(audio_path, language=\"ur\" if language == \"urdu\" else \"en\")\n",
        "        text = result.get(\"text\", \"\").strip()\n",
        "        if not text:\n",
        "            return \"âŒ Ø¢ÚˆÛŒÙˆ Ú©Ùˆ Ø³Ù…Ø¬Ú¾Ù†Û’ Ù…ÛŒÚº Ù†Ø§Ú©Ø§Ù…ÛŒ\" if language == \"urdu\" else \"âŒ Could not transcribe audio\", None\n",
        "\n",
        "        # Emotion detection prompt\n",
        "        emotion_list = [\"Ø®ÙˆØ´ÛŒ\", \"Ø§Ø¯Ø§Ø³ÛŒ\", \"ØºØµÛ\", \"ØªÚ¾Ú©Ø§ÙˆÙ¹\", \"Ø¬Ø°Ø¨Ø§ØªÛŒ\", \"Ù¾Ø± Ø³Ú©ÙˆÙ†\"] if language == \"urdu\" else \\\n",
        "                       [\"happy\", \"sad\", \"angry\", \"tired\", \"exhausted\", \"nostalgic\", \"motivated\", \"demotivated\", \"excited\", \"calm\", \"anxious\"]\n",
        "\n",
        "        prompt = (\n",
        "            f\"Ù…Ù†Ø¯Ø±Ø¬Û Ø°ÛŒÙ„ Ø¹Ø¨Ø§Ø±Øª Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø¬Ø°Ø¨Ø§Øª Ú©Ø§ Ø§Ù†Ø¯Ø§Ø²Û Ù„Ú¯Ø§Ø¦ÛŒÚºÛ” Ø§Ù† Ù…ÛŒÚº Ø³Û’ Ø§ÛŒÚ© Ú©Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±ÛŒÚº: {emotion_list}.\\n\"\n",
        "            f\"Ø¹Ø¨Ø§Ø±Øª: \\\"{text}\\\"\\n\"\n",
        "            f\"Ø¬ÙˆØ§Ø¨ Ù…ÛŒÚº Ù„Ú©Ú¾ÛŒÚº:\\n- Emotion:\\n- Reason:\"\n",
        "        ) if language == \"urdu\" else (\n",
        "            f\"From the following text, detect the most likely human emotion expressed.\\n\"\n",
        "            f\"Choose one emotion from: {emotion_list}.\\n\"\n",
        "            f\"Text: \\\"{text}\\\"\\n\"\n",
        "            f\"Respond with:\\n- Emotion:\\n- Reason:\"\n",
        "        )\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        emotion_analysis = response.choices[0].message.content.strip()\n",
        "        emotion_line = [line for line in emotion_analysis.splitlines() if \"Emotion\" in line]\n",
        "        if not emotion_line:\n",
        "            return \"âŒ Ø¬Ø°Ø¨Û Ø´Ù†Ø§Ø®Øª Ù†Û ÛÙˆ Ø³Ú©Ø§\" if language == \"urdu\" else \"âŒ Could not detect emotion\", None\n",
        "\n",
        "        emotion = emotion_line[0].split(\":\")[1].strip()\n",
        "        playlist = get_playlist(emotion, language)\n",
        "        poem = get_poem(emotion, language)\n",
        "        gif_url = search_tenor_gif(emotion)\n",
        "\n",
        "        playlist_md = \"\\n\".join(playlist) if playlist else \"âš ï¸ Ú©ÙˆØ¦ÛŒ Ú¯Ø§Ù†Ø§ Ù†ÛÛŒÚº Ù…Ù„Ø§\" if language == \"urdu\" else \"âš ï¸ No songs found.\"\n",
        "\n",
        "        # âœ… STEP 9: Return Beautifully Formatted Output\n",
        "        if language == \"urdu\":\n",
        "            output_text = f\"\"\"\n",
        "<div dir=\"rtl\" style=\"text-align: right; font-family: 'Noto Nastaliq Urdu', serif; font-size: 16px\">\n",
        "\n",
        "### ğŸ“‹ Ù…ØªÙ†\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ­ Ø¬Ø°Ø¨Ø§ØªÛŒ ØªØ¬Ø²ÛŒÛ\n",
        "{emotion_analysis}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§ Ú¯Ø§Ù†Û’ (Ø¬Ø°Ø¨Û: {emotion})\n",
        "{playlist_md}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“œ Ù†Ø¸Ù…\n",
        "{poem}\n",
        "\n",
        "</div>\n",
        "\"\"\"\n",
        "        else:\n",
        "            output_text = f\"\"\"\n",
        "### ğŸ“ Transcription\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ­ Emotion Analysis\n",
        "{emotion_analysis}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§ Playlist for *{emotion}*\n",
        "{playlist_md}\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“œ Poem\n",
        "{poem}\n",
        "\"\"\"\n",
        "        return output_text, gif_url\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Ø®Ø±Ø§Ø¨ÛŒ: {str(e)}\" if language == \"urdu\" else f\"âŒ Error: {str(e)}\", None\n",
        "\n",
        "# âœ… STEP 10: Gradio App\n",
        "gr.Interface(\n",
        "    fn=analyze_emotion,\n",
        "    inputs=[\n",
        "        gr.Radio([\"english\", \"urdu\"], label=\"ğŸŒ Language / Ø²Ø¨Ø§Ù† Ù…Ù†ØªØ®Ø¨ Ú©Ø±ÛŒÚº\"),\n",
        "        gr.Audio(type=\"filepath\", label=\"ğŸ¤ Upload or Record Voice\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"ğŸ“‹ Output\"),\n",
        "        gr.Image(label=\"ğŸ–¼ï¸ Mood GIF\")\n",
        "    ],\n",
        "    title=\"ğŸ™ï¸ Voice-to-Emotion: Pakistani Songs + Urdu Poetry\",\n",
        "    description=\"ğŸ§ Upload voice â†’ Transcribe â†’ Detect emotion â†’ Get a themed playlist, AI poem, and GIF ğŸ­\"\n",
        ").launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m7YscDQCLACt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
